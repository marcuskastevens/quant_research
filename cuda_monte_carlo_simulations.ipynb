{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 2060 with Max-Q Design\n",
      "Multiprocessors (SMs): 30\n",
      "Max Threads per SM: 2048\n",
      "Total Max Threads: 61440\n",
      "Max Threads per Block: 1024\n",
      "Max Blocks per SM: 2\n",
      "Total Max Blocks: 60\n"
     ]
    }
   ],
   "source": [
    "def summarize_device() -> None:\n",
    "\n",
    "    device = cuda.get_current_device()\n",
    "\n",
    "    # Most GPUs have 2048 per SM (NVIDIA spec)\n",
    "    max_threads_per_sm = 2048\n",
    "    multiprocessors = device.MULTIPROCESSOR_COUNT\n",
    "    total_max_threads = max_threads_per_sm * multiprocessors\n",
    "    max_threads_per_block = device.MAX_THREADS_PER_BLOCK\n",
    "    max_blocks_per_sm = max_threads_per_sm // max_threads_per_block  \n",
    "    total_max_blocks = multiprocessors * max_blocks_per_sm  \n",
    "\n",
    "    print(f\"Device: {device.name.decode()}\")\n",
    "    print(f\"Multiprocessors (SMs): {multiprocessors}\")\n",
    "    print(f\"Max Threads per SM: {max_threads_per_sm}\")\n",
    "    print(f\"Total Max Threads: {total_max_threads}\")\n",
    "    print(f\"Max Threads per Block: {max_threads_per_block}\")\n",
    "    print(f\"Max Blocks per SM: {max_blocks_per_sm}\")\n",
    "    print(f\"Total Max Blocks: {total_max_blocks}\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "summarize_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def monte_carlo_simulation(simulation, random_values):\n",
    "    \"\"\"\n",
    "    Monte Carlo simulation using CUDA.\n",
    "    \n",
    "    Parameters:\n",
    "        simulation (device array): Output array to store results and be modified in-place.\n",
    "        random_values (device array): Pre-generated random values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get 2D thread indices\n",
    "    i, j = cuda.grid(2)\n",
    "    \n",
    "    # Check bounds to avoid out-of-bounds errors\n",
    "    if i < simulation.shape[0] and j < simulation.shape[1]:\n",
    "        simulation[i, j] = random_values[i, j]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_38928\\3289763641.py:14: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
      "  blocks_per_grid_x = np.math.ceil(rows / threads_per_block[0])\n",
      "C:\\Users\\marcu\\AppData\\Local\\Temp\\ipykernel_38928\\3289763641.py:15: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
      "  blocks_per_grid_y = np.math.ceil(cols / threads_per_block[1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 2 2 2]\n",
      " [1 1 2 1 1]\n",
      " [2 2 2 2 2]\n",
      " [2 1 1 1 2]\n",
      " [2 2 1 2 1]]\n"
     ]
    }
   ],
   "source": [
    "# Matrix size\n",
    "rows, cols = 1_000_000, 100\n",
    "\n",
    "# Host-side random number generation (only 0 or 1)\n",
    "random_values = np.random.choice([1, 2], size=(rows, cols)).astype(np.int32)\n",
    "\n",
    "# Allocate device memory for simulation and random values\n",
    "d_simulation = cuda.to_device(np.empty((rows, cols), dtype=np.int32))  \n",
    "d_random_values = cuda.to_device(random_values)\n",
    "\n",
    "# Define CUDA grid size (Each block has 16x16 threads)\n",
    "max_threads_per_block: int = cuda.get_current_device().MAX_THREADS_PER_BLOCK\n",
    "threads_per_block = (int(np.sqrt(max_threads_per_block)), int(np.sqrt(max_threads_per_block)))\n",
    "blocks_per_grid_x = np.math.ceil(rows / threads_per_block[0])\n",
    "blocks_per_grid_y = np.math.ceil(cols / threads_per_block[1])\n",
    "blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "# Launch CUDA kernel\n",
    "monte_carlo_simulation[blocks_per_grid, threads_per_block](d_simulation, d_random_values)\n",
    "\n",
    "# Copy results back to host\n",
    "simulation_result = d_simulation.copy_to_host()\n",
    "\n",
    "# Print part of the result for verification\n",
    "print(simulation_result[:5, :5])  # Print a small section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda, float32\n",
    "import math\n",
    "import numba.cuda.random as curand\n",
    "\n",
    "@cuda.jit\n",
    "def monte_carlo_option_pricing(S0, K, r, sigma, T, num_paths, rng_states, results):\n",
    "    \"\"\"\n",
    "    CUDA Kernel for Monte Carlo European Option Pricing using Black-Scholes.\n",
    "    \n",
    "    Each thread simulates one price path.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Thread index\n",
    "    idx = cuda.grid(1)\n",
    "    \n",
    "    if idx < num_paths:\n",
    "        dt = T  # Only one step for European option at expiry\n",
    "        dW = cuda.random.xoroshiro128p_normal_float32(rng_states, idx) * math.sqrt(dt)\n",
    "        \n",
    "        # Simulate asset price at maturity\n",
    "        S_T = S0 * math.exp((r - 0.5 * sigma ** 2) * dt + sigma * dW)\n",
    "\n",
    "        # Compute payoff: max(S_T - K, 0)\n",
    "        results[idx] = max(S_T - K, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European Call Option Price: 6.0391\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "S0 = 100                    # Initial stock price\n",
    "K = 110                     # Strike price\n",
    "r = 0.05                    # Risk-free rate\n",
    "sigma = 0.2                 # Volatility\n",
    "T = 1                       # Time to maturity in years\n",
    "num_paths = 10_000_000      # Number of Monte Carlo simulations\n",
    "\n",
    "# Allocate device memory\n",
    "d_results = cuda.device_array(num_paths, dtype=np.float32)\n",
    "rng_states = curand.create_xoroshiro128p_states(num_paths, seed=69)\n",
    "\n",
    "# Configure CUDA kernel\n",
    "threads_per_block = 32\n",
    "blocks_per_grid = (num_paths + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "# Run kernel\n",
    "monte_carlo_option_pricing[blocks_per_grid, threads_per_block](S0, K, r, sigma, T, num_paths, rng_states, d_results)\n",
    "\n",
    "# Copy results back to host\n",
    "results = d_results.copy_to_host()\n",
    "\n",
    "# Compute option price (discounted expected payoff)\n",
    "option_price = np.exp(-r * T) * np.mean(results)\n",
    "\n",
    "print(f\"European Call Option Price: {option_price:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
