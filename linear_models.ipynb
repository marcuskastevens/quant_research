{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearRegression Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(ABC):\n",
    "    \"\"\"\n",
    "    Abstract Base Class for Linear Regression Models.\n",
    "    Defines the core methods to be implemented by derived classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the regression model.\n",
    "        \n",
    "        Parameters:\n",
    "            X (np.ndarray): Design matrix (n_samples x n_features).\n",
    "            y (np.ndarray): Response variable (n_samples x 1).\n",
    "        \"\"\"\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.coefficients: Optional[np.ndarray] = None\n",
    "\n",
    "        return\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self) -> None:\n",
    "        \"\"\"\n",
    "        Compute the regression coefficients. Must be implemented by subclasses.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict response values for new data.\n",
    "        \n",
    "        Parameters:\n",
    "            X (np.ndarray): New data for prediction.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Predicted values.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _add_constant(self) -> None:\n",
    "        \"\"\"\n",
    "        Add a constant column to the design matrix for the intercept term.\n",
    "        \"\"\"\n",
    "\n",
    "        self.X = np.hstack((np.ones((self.X.shape[0], 1)), self.X))\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLS(LinearRegression):\n",
    "    \"\"\"\n",
    "    Generalized Least Squares Regression Model.\n",
    "    Handles heteroskedasticity and autocorrelation in residuals by incorporating the residual covariance matrix (omega).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        omega: Optional[np.ndarray] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the GLS model.\n",
    "        \n",
    "        Parameters:\n",
    "            X (np.ndarray): Design matrix (n_samples x n_features).\n",
    "            y (np.ndarray): Response variable (n_samples x 1).\n",
    "            omega (Optional[np.ndarray]): Covariance matrix of residuals (n_samples x n_samples). Defaults to None (OLS case).\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(X=X, y=y)\n",
    "        \n",
    "        self.omega = omega if omega is not None else np.eye(len(y))\n",
    "\n",
    "        return\n",
    "\n",
    "    def fit(self) -> None:\n",
    "        \"\"\"\n",
    "        Fit the GLS model using the generalized normal equation: (X'W^(-1)X)^(-1)X'W^(-1)y.\n",
    "        \"\"\"\n",
    "\n",
    "        self._add_constant()\n",
    "\n",
    "        # Store the inverse of the residual covariance matrix to optimize latency and avoid inverting the matrix twice \n",
    "        omega_inverse = np.linalg.inv(self.omega)\n",
    "\n",
    "        # Solve the GLS equation\n",
    "        self.coefficients = np.linalg.solve(self.X.T @ omega_inverse @ self.X, self.X.T @ omega_inverse @ self.y)\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict response values for new data.\n",
    "        \n",
    "        Parameters:\n",
    "            X (np.ndarray): New data for prediction.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Predicted values.\n",
    "        \"\"\"\n",
    "        \n",
    "        if X.shape[1] + 1 == self.X.shape[1]:\n",
    "            X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        return X @ self.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0146527197187467"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.random.randn(1_000, 1)\n",
    "X_train = np.random.randn(1_000, 10)\n",
    "\n",
    "y_test = np.random.randn(1_000, 1)\n",
    "X_test = np.random.randn(1_000, 10)\n",
    "\n",
    "gls: GLS = GLS(X=X_train, y=y_test)\n",
    "gls.fit()\n",
    "\n",
    "y_hat = gls.predict(X=X_test)\n",
    "\n",
    "np.var(y_hat - y_test, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS LinearRegression Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLS(GLS):\n",
    "    \"\"\"\n",
    "    Ordinary Least Squares Regression Model.\n",
    "    Inherits from LinearRegression and implements its methods.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the OLS model.\n",
    "        \n",
    "        Parameters:\n",
    "            X (np.ndarray): Design matrix (n_samples x n_features).\n",
    "            y (np.ndarray): Response variable (n_samples x 1).\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(X=X, y=y, omega=None)\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0263146477395808"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.random.randn(1_000, 1)\n",
    "X_train = np.random.randn(1_000, 10)\n",
    "\n",
    "y_test = np.random.randn(1_000, 1)\n",
    "X_test = np.random.randn(1_000, 10)\n",
    "\n",
    "ols: OLS = OLS(X=X_train, y=y_test)\n",
    "ols.fit()\n",
    "\n",
    "y_hat = ols.predict(X_test)\n",
    "\n",
    "np.var(y_hat - y_test, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLS LinearRegression Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLS(LinearRegression):\n",
    "    \"\"\"\n",
    "    Generalized Least Squares Regression Model.\n",
    "    Extends OLS to handle heteroskedasticity and autocorrelation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, omega: np.ndarray):\n",
    "        \"\"\"\n",
    "        Initialize the GLS model.\n",
    "        \n",
    "        Parameters:\n",
    "            X (np.ndarray): Design matrix (n_samples x n_features).\n",
    "            y (np.ndarray): Response variable (n_samples x 1).\n",
    "            omega (np.ndarray): Covariance matrix of residuals (n_samples x n_samples).\n",
    "        \"\"\"\n",
    "        super().__init__(X, y)\n",
    "        self.omega = omega  # Covariance matrix of residuals\n",
    "        self.coefficients = None\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Fit the GLS model by solving the generalized normal equation.\n",
    "        \"\"\"\n",
    "        self._add_constant()  # Add intercept term\n",
    "        omega_inv = np.linalg.inv(self.omega)  # Inverse of covariance matrix\n",
    "        XTWX = self.X.T @ omega_inv @ self.X\n",
    "        XTWy = self.X.T @ omega_inv @ self.y\n",
    "        self.coefficients = np.linalg.inv(XTWX) @ XTWy\n",
    "\n",
    "    def predict(self, X_new: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict response values for new data.\n",
    "        \n",
    "        Parameters:\n",
    "            X_new (np.ndarray): New data for prediction.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Predicted values.\n",
    "        \"\"\"\n",
    "        if X_new.shape[1] + 1 == self.X.shape[1]:\n",
    "            X_new = np.hstack((np.ones((X_new.shape[0], 1)), X_new))\n",
    "        return X_new @ self.coefficients\n",
    "\n",
    "class PanelRegression:\n",
    "    \"\"\"\n",
    "    Panel Regression Model for cross-sectional and time-series data.\n",
    "    Leverages GLS for panel data over multiple time periods.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray, omega: np.ndarray):\n",
    "        \"\"\"\n",
    "        Initialize the Panel Regression model.\n",
    "        \n",
    "        Parameters:\n",
    "            X (np.ndarray): Design matrix (n_entities x n_features x n_time_periods).\n",
    "            y (np.ndarray): Response variable (n_entities x n_time_periods).\n",
    "            omega (np.ndarray): Covariance matrix of residuals (n_entities x n_entities).\n",
    "        \"\"\"\n",
    "        self.X = X  # 3D design matrix\n",
    "        self.y = y  # Response matrix\n",
    "        self.omega = omega  # Covariance matrix\n",
    "        self.coefficients = None\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Fit the Panel Regression model by applying GLS across time periods.\n",
    "        \"\"\"\n",
    "        n_entities, n_features, n_time_periods = self.X.shape\n",
    "        self.coefficients = np.zeros((n_features + 1, n_time_periods))  # Including intercept\n",
    "\n",
    "        for t in range(n_time_periods):\n",
    "            X_t = self.X[:, :, t]\n",
    "            y_t = self.y[:, t]\n",
    "            gls = GLS(X_t, y_t, self.omega)\n",
    "            gls.fit()\n",
    "            self.coefficients[:, t] = gls.coefficients.flatten()\n",
    "\n",
    "    def predict(self, X_new: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict response values for new data across all time periods.\n",
    "        \n",
    "        Parameters:\n",
    "            X_new (np.ndarray): New data for prediction (n_entities x n_features x n_time_periods).\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Predicted values (n_entities x n_time_periods).\n",
    "        \"\"\"\n",
    "        n_entities, n_features, n_time_periods = X_new.shape\n",
    "        predictions = np.zeros((n_entities, n_time_periods))\n",
    "\n",
    "        for t in range(n_time_periods):\n",
    "            X_t = X_new[:, :, t]\n",
    "            if X_t.shape[1] + 1 == self.coefficients.shape[0]:\n",
    "                X_t = np.hstack((np.ones((X_t.shape[0], 1)), X_t))\n",
    "            predictions[:, t] = X_t @ self.coefficients[:, t]\n",
    "\n",
    "        return predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
